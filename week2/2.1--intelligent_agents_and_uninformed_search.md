## 推荐阅读资料：

Artificial Intelligence: A Modern Approach, 3rd Edition Russell & Norvig, Chapters 2, 3.1-3.4.

Please note: This book is strongly suggested but is not mandatory to complete the course.



## 课堂讲解：

Recall from the previous lectures．

我们感兴趣的是理性的，智能的代理　（**rational, intelligent agents**）.

And this will be our approach to AI in this course.

本节中, let's examine different aspects　related to rational agents.

And, specifically, agent environments in which the agent evolves.

And how this affects our design of intelligent, rational agents.

So let's dive in.

首先，agent的定义．什么是agent?

An agent: anything that can be viewed

as perceiving(感知) its environment through sensors,　

and acting upon that environment through **actuators**（执行器）.

An agents can be represented with this diagram in which we

have the environment and the agent.

The agent box actually has some sensors in it

that sense the environment, and gets percepts

from the environment.

And the agent can have actuators that actually

act upon that environment.

Those generating actions are deciding what to do

and generating actions.



So the first part here allows the agent actually

to sense the world-- sense the world in which it evolves.

And the second part actually is about acting upon that world.

So this is acting.

So in the middle, you have a product in which

the agent would do what?

Would do thinking and deliberating.

Here the agent, given what it's observed or sensed

from the world, it will be thinking, deliberating,

or deciding-- another term for deciding what to do,

based on what it senses.



因此，一般而言, 你可看见that as a cycle for the agent

in which it perceives the environment, decides

think what to do, act, and so on and so forth.

So we have a kind of loop or cycle

happening here of perception（感知）, thinking, and acting

upon that environment.



The last aspect to mention about agent,

is that they are actually made up of two main components.

And these are the **architecture** and the **system**, or the program.

含义：The architecture is the 物理组成.

This is the hardware of the agent.

This is the box that you have here,

and to which the set of sensors and actuators belongs to.

So this is the physical object that is linked to the agent.

Or this is the agent hardware itself.



So the program is actually the 心 (mind) of the agent.

这是deliberation和 thinking发生的地方．

And this is happening actually here,

where you have-- you get the percept from the sensors,

from the physical, but then that agent

has to think about what to do, what

would be the world if he does, or that, et cetera.

So we have this way two main components

that are not only complimentary, they have to be compatible（它们必须兼容）.

因此 the program is limited by the architecture make up,

and they have to be working together in harmony.

So basically, you can't, for example,

ask your intelligent agent to dance if it's just

a simple box on your table.

It would have to be some kind of compatibility between the two

pieces.

Example of agents include human agent,

that have as sensors the eyes, the ears, and other organs.

The actuators are the hands, legs, mouth

and other body parts.

Or body agents has as sensors the camera, infrared,

range finders, and other kinds of sensor

that allows them to move safely in their environment.

And the actuators are the various motors

that makes the robot moves.

Actually agents are everywhere.

This includes a simple thermostat

that maintains the room temperature; to your cell

phone that includes a lot of functionality

such as e-mails, web pages, the weather; to the vacuum

cleaner that you could program to go around your house

to clean your house; to robot that is as we said.

The Alexa Echo which is one of the most recent additions

that you could add to your house,

that can 为你点菜, play your favorite music,

maintain your shopping list, switch your lights off, 为你预约一辆滴滴车, 等等.

一辆自动驾驶的汽车, which is one of the most advanced AI agents

that actually is a car driving itself in the street,

1. perceiving its environment in terms of pedestrians, traffic,

2. roads, other cars, and acting upon that by moving from one

3. point to another one in the city.

   And finally, the human agent that

   actually the most intelligent agent out there.

   Let's take a very simple example of a vacuum

   cleaner agent that actually evolves in a small environment

   in which we have two rooms, Room A and Room B,

   and potentially some dirt in the rooms to clean up.

   So the percept of the vacuum cleaner in this environment

   is the location and the content of the room.

   For example, if the vacuum cleaner

   has *two sensors*, a sensor for dirt and a sensor for location,

   it could create a percept as a pair.

   A, dirty, for example, is an example

   to say that-- is a percept to say that the room A is dirty.

   The action that the vacuum cleaner accomplish

   are going left, going right, suck the dirt,

   or do nothing if everything is clean.

   And finally, we are defining actually

   an **agent function** that actually is

   a mapping between the set of percepts

   and the set of actions.

   And this we could write in a table

   that actually has a mapping between percepts and actions.

   So for example, if A is clean, then go right.

   If A is dirty, then suck the dirt.

   If B is clean, go left, then check whether there

   is dirt afterwards in the left.

   And if B is dirty, then suck it up.

   So we're going to-- this is a simple actually precept action

   table pairs in which we have simple precepts, not

   a sequence of words but just simple precepts on the left,

   and the corresponding actions.

   So given this, the agent will just

   need to look up in this table, and depending

   on what it is perceiving from the environment

   through its sensors, it will define what it's going to do.

   So we could actually make this table longer

   by not only keeping the precepts single percept by themselves,

   but having combinations of percepts or sequence

   of percepts.

   For example, if A was dirty, and then A, it became clean,

   what to do?

   Right?

   So going to extend this table to not only

   maintain the percept, but also sequences of percepts.

   So we are interested in well-behaved agents.

   And these are rational that are defined according to Russell

   and Norvig as follows, "**For each possible percept sequence,**

   **a rational agent should select an action that**

   **is expected to maximize its performance measure,**

   **given the evidence provided by the percept sequence**

   **and whatever background knowledge or ability knowledge**

   **the agent has**."

   So we want this agent to be rational in the sense

   that it's going to do its best, given

   what it is observing and given whatever background knowledge

   the agent has.

   More specifically, we define rationality

   relative to a performance measure.

   And we judge rationality based on the performance measure

   that defines the criterion of success.

   The agent prior knowledge of the environment,

   the possible actions that the agent can perform,

   and finally the agent precept sequence to date.

   So when we define rational agents,

   we group these properties under the acronym PEAS, which

   stands for Performance, Environment, Actuators,

   and Sensors.

   Which is actually the problem specifications

   for the task environment that the rational agents

   is meant to solve.

   So let's define PEAS for some intelligent agents.

   

   And let's start with the self-driving car.

   So for self-driving car, passenger

   would care about the full performance, which

   could be the safety of the passenger, its comfort,

   and also the time to destination.

   We care about the legal drive, we

   don't want a self-driving car that

   crosses red lights or that harms pedestrian.

   The environment of a self-driving car

   is all the roads, the other cars, pedestrians, road signs,

   and so on and so forth.

   The actuators are everything that

   makes the car move or interact with the environment,

   such as the steering, accelerator, brake, signal,

   horn, et cetera.

   And finally, the sensors of the self-driving car

   is actually [INAUDIBLE] with a lot of different sensors.

   These include a camera, a sonar, a GPS, a speedometer,

   an odometer(里程表), and a keyboard, along with other kinds

   of sensors that allow the car really to perceive the environment.

   

   第二个例子, vacuum cleaner.

   You're probably familiar with the iRobot Roomba series that

   started about 10 years ago, to clean--

   that you could put in your room to clean the floor.

   The performance of the vacuum cleaner

   could be measured in terms of cleanness

   of the room, the efficiency-- that is the distance traveled

   to clean-- or the battery life.

   You care also about the performance

   in terms of security.

   Putting a device in your room that actually has eyes,

   it has cameras, and it is potentially connected

   to the wi-fi or internet, and you

   don't want this to be hacked.

   So security is a very important aspect of this device

   before you add it to your house.

   The environment includes anything in the room,

   such as 桌子, 木地板, 地毯,和不同物体.

   Your kid's lego could be swallowed by the machines so,

   the environment is anything around

   in the room that actually constitutes the environment

   of the vacuum cleaner.

   最后, the actuators are actually

   the hardware of the vacuum.

   包括轮子,各种刷子,

   除去脏污的吸尘器.

   最后the vacuum cleaner,

   includes several sensors.

   包括摄像头，脏污探测器,绝壁探测器-- they

   didn't want the Roomba to go down the stairs,

   fall down the stairs-- 隆起物探测器（以免碰上家具）

   so it has to really detect whenever there is something

   that the Roomba would hit.

   Finally, the sensors include a camera, a dirt detection

   sensor, the cliff sensors so the vacuum cleaner doesn't go down

   the stairs, the bump sensor that allows you

   to-- that allows the vacuum not to bump

   into all of your furniture.

   And finally an 红外墙壁探测器

   that allows to detect the size and the limits of the room.

   

   因此，我们看见了两个agents的实际例子

   with two examples of environment,

   the street and the room.

   实际上，我们可以将环境分为不同的类型.

   And this includes whether the environment

   is fully observable, in which an agent's sensors give it

   access to the full picture.

   That is, the complete state of the environment

   at each point in time.

   This is versus partially observable,

   例如the self-driving car,

   that do not have access, for example, to what's

   going on in three blocks away, or what's

   going on behind the truck.

   An environment is deterministic when

   the next state of the environment

   is completely determined by the current state,

   and the action executed by the.

   Agent if the environment is deterministic

   except for the actions of the other agents,

   then the environment is called strategic.

   So basically, 一辆车不能预测其他车的行为，也不能预测交通状况.

   

   the opposite of deterministic is non-deterministic,

   or what we call stochastic, in which

   uncertainty about outcomes is modeled or quantified

   in terms of probabilities.

   We have this possibility of making

   this action for the agent.

   And although it can also be episodic or sequential,

   in which the agent experience

   is divided into atomic episodes.

   Each episode consists of the agent perceiving and then

   performing a single action.

   And the choice of action in each episode

   depends only on the episode itself.

   The environment is called static vs. dynamic

   if the environment is unchanged why the agent is deliberating

   or thinking.

   The environment is called **semi-dynamic**

   if the environment itself does not

   change with the passage of time, but the agent's performance

   score does.

   So everything is the same, but the score is going down

   as time goes down.

   This is for example, the case of chess with a clock.

   The environment is **discrete** versus **continuous**

   when a limited number of distinct, clearly defined,

   percepts and actions is there.

   For example, checkers is an example

   of discrete environment, while self-driving car evolves

   a continuous one, in terms of both the actions and also

   the time.

   A single agent-- we talk also about single agent

   versus multi-agent environments, because whenever the agent is

   by itself or with other agents.

   We also talk about **simple** versus **multi-agents**.

   In a simple agent, an agent is operating by itself

   in an environment, there are no other agents operating there.

   And finally known versus unknown,

   in which the designer of the agent

   may or may not have knowledge about the environment make up.

   If the environment is unknown, then the agent

   will need to know how it works in order to decide.

   So this is for example, a case of a Roomba

   that you place in a room, so when you design one,

   the designer of the Roomba does not know in which room

   the Roomba would be put.

   So the Roomba would be using different kinds of sensors,

   including an infrared wall sensor,

   to define with other limits and the distance interval.

   So if we don't know the room, the designer

   has to embed some intelligence in the agent in order

   to actually get familiar with the environment in which it

   will evolve.