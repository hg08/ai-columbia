# 线性模型

上一讲中, 我们开始了机器学习话题．
机器学习是今天的人工智能的一个主要方法.
We also developed a basic understanding of the different concepts of machine
learning.
And also started one of the methods of machine learning,
which is k-Nearest Neighbors.
It turned out that this method is widely used,
but also developed non-linear models.
In this lecture, we're going to talk about linear models which has been
widely used in statistics and machine learning for a long time.
In this lecture we are going to talk about two kinds of linear models.
第一个就是linear regression.
We're going to talk about the the history of linear regression that has roots in
statistics.
We're going to talk about linear regression with least squares.
And talk about linear regression的两种方法,
one using matrix of presentation through the normal equation.
And the second one is an iterative method using gradient descent.
We're going to compare both methods at the end.
Second, we're going to talk about linear classification.
And present the method of the perceptron, its history, examples, and
finally the algorithm.
Let us first recall what is supervised learning.
So suppose we dispose of training data.
Training data is a set of examples that are feature values along with the labels.
So we have this data,
and this data is defined in R^d which is the space of the d features we have.
We spoke about two kinds of supervised learning, regression and classification.
In regression we want to regress on a real value.
So I want to be able to map the input values, which is the space of the feature
values in R^d, through to outward space which is a real value.
In classification we care about mapping the Input value into a discrete
value which is minus 1 or plus 1.
Which is the classification in the case of binary classifications, of course.
Okay, so I'm trying to find models and this model's actually maps.
These are the two models, one maps from the feature values into R.
And the other one maps from the feature values into a set of binary values.
Let us first start with linear regression,
which is a very popular technique rooted in statistics.
The most commonly used method in linear regression is called least square used as
early as 1795 by Gauss.
It was later on reinvented by Legendre in in 1805.
Linear regression has been widely used in different fields including in
astronomy to study the large scale of the universe.
For example, find the regression that goes through most of the stars, or
measure different distances, or
estimate the distance between different parts of the universe.
It is still a very useful technique today.

## 线性回归如何工作?

Again given the training data set of pairs of feature values, labels, right.
So the features are in 
$$
\R^d,  \nonumber
$$
the labels are in 
$$
\R, \nonumber
$$
well, we get used to this kind of framework.
我们有多个例子的一个集合（as we said last time),
我们有多个特征值的一个集合, 且我们有一个标签.
回归的目标就是： 找到一个函数
$$
f, \nonumber
$$
即特征到标签的一个映射(输入到输出的一个映射).
We talk about linear regression because the regression model that we're trying to
build, which is the function F,
is actually linear because it can be represented by a linear function.
For example, in the case of a data set with only one feature and one label,
we plug this data into a two-dimensional space in which we try to find
the best line that fits the data points.
In other words that finds a function that maps the y in function of x.
So what we're trying to do is to find this line here
that goes through most of the data points.
The function is then a linear function, a function of x,
in which that we could write as F(x), equal to the equation of a line,
which will be a constant beta0 plus beta1 x, right?
So this is a line where beta0 is the offset or the intercept.
In the second example,
we have data in this case laying in to a three-dimensional space.
We have x1, x2.
We also have the label y, and you want to find some function F(x).
That is a combination of the function x of the features x1 and x2,
that predicts best y which would be in this case the hyperplane
that you see here that goes through most of the data points in R^3.
In this case the function of x would be something in terms of x1 and
x2 which would be because you're at beta1 plus 1, plus beta2 x2.
So these two are the equations of the linear function,
one is the first function is an R2.
And the second is the second function is in R3.
Let's develop now a method to build a linear regression model.
So if you have seen in the previous example and
their model is a function F(x) that is linear in x, right.
So I could write it in a more general fashion
as F(x) is the beta0 plus the sum of the betaJ xJ.
Which means that we're going to sum over all the x features
times what we call the weight.
Or a parameter which is beta.
So for each feature we have a beta weight corresponding to it.
In this case,
learning the linear model means simply learning the betas of the equation, right.
The equation that is actually the linear model that goes through the data points.
One of the most used methods for finding this beta is called the least square,
which uses what we call the least square loss.
So remember the loss is, so we build the function,
this function tries to map the inputs to the output.
But it's not the perfect function so we try to see what kind of errors or
how much we lose by using this function.
Remember, we do have,
when we do a learning, in the learning phase we do have the y labels.
And we build the function of maps the x’s to the y’s.
This function is not perfect.
So we could compare the y that is the true label, or the true outcome of the example,
with the estimated y or the function that is F(x) applied to this example.
So we spoke about the loss function that actually
compares the true label to the predicted label.
Predicted with what?
With our function F(x).
So in this case, a simple loss function would be to
just do the difference between the true label and the predicted label.
And take the square to not worry about the negative sign, okay.
So given this loss function, which actually if you go back to our previous
example, means that we're going to look at the difference between given a data point,
Given a data point, we know for the data point what was the true y label, right?
The estimated function at this point would be this value.
So we're going to take the difference between the true label and the function,
which is the projection of the point,
point on the function that goes through the data points.
One of the methods to build linear regression models is called least squares.
So recall in the previous lecture,
we spoke about the loss function which is how much error is our function making?
The way to know how much error, or how much how good is our function,
is to see the difference between the true label versus the expected label,
which is the prediction made by the function F, our model F.
So you could do the difference between the y_i and F(xi),
which is the function applied to this at that point.
We'll square this as we said to avoid worrying about a negative sign
in case where y_i is bigger or is less than F(x_i), right.
So recall in the previous example, we had actually, we defined this function F(x),
which is our, this is our F(x), right, this function.
And what you want to do is to actually make little mistakes which means that if
we take a data point that has a true label y, right?
And when we apply the function F, we're going to get this point here.
And you want actually this distance to be not big so you want to minimize this
distance but you want to do it over all the data points in our examples.
So what you want to achieve is to actually minimize the loss over all the examples.
We want to be able to do as little errors as possible globally on all the data sets,
right?
So we define what we call the risk on the cost function, R.
And this cost function is simply the sum of the loss values over all
the data points.
So we are going to iterate from one to N where N is the number of examples.
And so we take the risk over all those points.
So this is the average risk.
We divide by two, just for convenience because this two
will later on cancel each other when we do the derivations.
Okay, let's take first the simple example where we have only one feature.
So for one feature as we have seen, we can write F(x) as beta0 plus beta1 x.
This is the equation of a line.
We want to find beta0 and beta1, right?
So the way to do it, so we want to minimize the cost function or the risk R,
as we said, which is a different, the loss function over all the examples.
So we're going to replace the function F(x) here by this value here, right?
Which is the equation of a line which will make the risk function which is
a function of the beta values.
This is what you want to find.
You want to find the beta that minimizes the risk function R.
Okay, so I got to a place of F(x_i) by beta0 plus beta1 x1 for
each of the learning examples, i, right?
So with the same minus we have minus because zero minus become beta1 xi.
And the goal is to find beta0 and beta1 that minimize this risk function here.
So see how when you plug in the shape of the function F,
which is a linear function of the feature x, right.
We get this new risk function that looks like this.
Notice that this function is a quadratic function?
It will look like a bowl if you plot it.
Just like shown in this picture.
So the function will look like a bowl with the minimum value or
the optimal value for beta0 and beta1 would be at the bottom of the ball.
So there is only one optimal solution that minimizes the risk in this case.
So the figure on the left also shows
another presentations of the bowl function.
With contours so we see that there is only one single point for
which we could get them.
For which we have a beta0 and
beta1 that minimizes the function of the risk function R.
Okay great, so if we introduce another notation,
we talk about arguing of beta of this risk function means that
find that betas that minimizes this risk function and this is our goal.
How to to find beta0 and
beta1 in the case of one-dimensional space that minimize this risk function R.
So we want to minimize a risk function R, which is a function of beta0 and beta1.
To minimize this function which means looking for
this bottom of the bowl function.
We need to put the partial derivative of R at beta0 to zero and
the partial derivative of the risk R at beta1 equal to zero.
So going to do some calculations here.
The partial derivative of the risk function R at beta0 could be stated as
this, this would be actually derivative of this function.
I would see that the 2s will cancel, we're going to
put this partial derivative at beta0 equal to zero.
This will bring us to this formation of beta0 in which we have beta0 expressed
in function of the yes, in function of the beta1, and in function of the xes.
This is the formula for a beta0.
We perform similar derivations to calculate
the partial derivative of the function R in terms of beta1, so
we calculate the derivation of the risk function.
We simplify the risk function and we set it equal to zero.
This will lead to the formation of beta1, in which you plug in the beta0, and
we get finally a beta1 that only depends on the data
itself, which is the features and the labels.
Given beta1, we could always go back and plug in that into beta0 and
we also express beta0 in this case in function of the data we have.
So now if we have more than one feature,
we're going to try to find a function F that is linear in x.
So we have as we said before F(x) is beta0 plus the sum
over all the dimensions, right, of beta_j, x_j.
Betas are the parameters.
We need to find the betas that actually minimizes the risk function one more time.
Okay, so you could see that you have here in this case.
So this is the loss per point we're going to sum the loss over all the data points.
But then for each function we're going, so
we are just plugging in this function here.
So we're going to go through the sum of the beta_j, x_j for each of the point and
see how we are doing as compared to the true label.
So this start to be a little bit more complicated doing derivations on this
function would be a little bit more complicated.
And it's better in this case to switch to a more elegant way to write it,
which is write it with matrices.


# 正规方程和梯度下降法

So here is matrix presentation of the problem.
Suppose we dispose of again our feature values so
we called this are our features.
We have the label Y write that to put as a convector Y.
We are all we have also the beater values, each beta for
a feature except for beta0 which is the intercept right.
So we add one columnn in X which is a one column.
Why do we do that?
Because at some point what we're going to do is to write F of X,
as something that is beta0 plus, the sum of beta_J X_J, right?
So the way to obtain sum of beta_J, X_J over all, the features
is to do multiplication of this each row in X by the columnn in beta right?
But to ensure that we have beta0, we add one at the beginning of each row so
as we get this beta0 recovered in the formulation.
So given this setting, we have X as the feature vector, we have Y the labels and
we have the betas us.
You want the problem in a an elegant fashion, so
given the matrix a presentation,
we could do an analytical solution which is using the normal equation.
So we want to find d plus one betas, beta0, beta1 through beta d
to minimize the risk function R that in this case we could express as
the risk we can hear in function of beta, which is simply just another way to write
the risk function we had before in which we use the difference between the Y,
which is the vector of the labels, minus X times beta which is the result
of applying the betas to the feature values X.
Okay, this could be written as this formulation here,
we take the partial derivative of R for the vector B, we get this derivation here.
We need to ensure that the second derivative of
R at beta is positive definite which ensures that beta is minimum.
And we solve for beta we get the unique solution,
beta as X transpose X minus one which is the inverse X transpose one.
Which means that given the data, the learning data, we could calculate
the betas straightforwardly just by calculating the transpose of the matrix X
which is the features, times X we inverse the result and we multiply
this by X transpose, we multiply by the labels Y and we got the betas
So this is like the analytical exact solution to give the beta in a straightforward fashion.
this is lead us to the unique solution of beta which only depends on X and
Y which are the data only thewe have.
So this is pretty straight forward given the data set.
You just need to plug in the features and the label.
The labels into this formula to get the vectors be done.
This is not always possible.
It's an article it's great but it's not always possible.
It depends a lot on whether X transpose X is invertible.
Another way to calculate the betas is to do the method gradient descent.
This method means that we're going to descent the curve of the risk,
until we reach the sweet spot of the minimal value of the risk.
So as an example for which we have only one feature, so
we have only one beta, right.
And we have the risk function R, okay.
So we're going to start anywhere on the curve,
we're going to descend until we reach the minimal points.
So clearly here what we're looking to achieve is to get the beta here for
which we have the risk at it's minimal value.
So suppose we start at this point here the idea is to descend the curve,
right descend the curve until we reach the point that we are looking for.
So way to descend is to use the slope which is a derivative of the function.
The risk function, the risk function at each point.
Golden descent is an optimization method that actually tries to find and
descend the curve to reach the best beta.
So which would be the sweet spot of the best, the optimal value on the function R.
So we're going to repeat at the convergence which means that,
we found the best value so convergence happens where we
actually we are not anymore changing the risk, the risk function.
So we reached the sweet spot.
We update what?
We update simultaneously all the betas that we're talking about.
So in this case we're talking about, changing the beta0 and
beta1 simultaneously this is important because you want to be able to move
the point on the curve based on all the betas that you're using.
So the way to change the beta is take the old value of the beta of to change.
We don't you know I think we don't because here or minus something so
I'm going to descend right and
take beta0 minus something I'm going to also descend on the beta1.
What do I subtract I said this subtract the slope
which allows me actually to go down the curve.
I'm going to play by alpha which is actually called the learning grade.
In the linear case we know how to going to calculate the derivative of risk at beta0
and beta1, this is something we have seen in the previous slide.
So let's generalize it.
The way to generalize it is to actually.
repeat until convergence, update simultaneously,
all the betas, right, by subtracting from each beta its alpha
times the derivative of the function R, which is in this case a linear function.
At beta0 and here by subtracting the derivative of R at beta1.
So that was the second way to get the betas the first I was I recall it was
about using an analytical method take the betas, with just the data you could
calculate the exact value of the betas, in the second way, we're going
iteratively refine to betas until we get the best parameters of the linear model.
So we have seen two methods the methods of analytical approach of normal equation and
the iterative approach using gradient descent.
In the analytical approach with normal equation we don't need to specify
a convergence rate, or iterate we just have a function of four
betas we plug in the data and we got our vector betas.
However this method only works if we have X transpose X,
invertible because this is a part of the calculations of betas.
Also this method is very slow.
If we have a high dimensional space and could be as low as D to the cube,
to calculate the inverse of X transpose X.
So it's just time consuming, however if the X transpose X is invertible,
then we got the calculation in a straight away.
The intuitive approach with got in descent is effective and
efficient even in high dimensions.
But it's iterative,
which means that you're going to start with some random point and
then you're going to refine it and then you convert to the best optimal solution.
So, sometimes it needs many many iterations to converge, and one
of the drawbacks of this method is that we still need to choose the rate alpha.
So let me explain this last point.
So in the produce, slide we saw that basically we have some
complex function that looks like this, and we want to
descent these function as we reach the point at the bottom of the curve right.
So reaching this point means that we're going to
descend the function here by going down and down and down.
And we multiply this change in the betas but
alpha times the derivative of the function at this point.
Which means that this rate that we have here alpha,
that we use each time to decrease the betas, is important.
Imagine if it's very, very small what will happen is that we're going to make very,
very, very, very baby steps, right, until we reach the minimal point.
However if the alpha is very big what happens is that
we have some scenario of ping pong where the value goes from here,
to here, to here, to here, to here and you probably would never converge.
So it's important to choose an appropriate
rate of to ensure the convergence of your function,
here not some practical considerations when you use linear regression.
First of all scaling is very important.
It's actually bring in the features of the same scale.
In the examples of bananas and oranges the weight could be in hundreds of
grams while the width could be in a few of centimeters.
So it's important to bring all the features to the same scale a little to
give them the same importance when you build the model.
So one way to scale is to subtract the mean and to divide,
divide by the standard deviations but there are other ways to do it.
Second consideration is learn the learning rate, so how to set the learning great we
need to make sure that we are not getting the learning way too small or too large.
The reason for that if you recall, the curve where we have,
in the minimal value presenting the best or two of what we are looking for
which is the minimal value of the risk.
So looking for the beat as it gives us the minimal value of the risk right?
So we say that we're going to use got in descent and we use is
important to use this rate because it tell us how fast we are descending the curve.
If you use very, very small off a rate that would happen is that you're going to
simply make very, very baby steps and really converge but really slowly so
making a lot of iterations to reach your point a bit here.
In contrast if you use a a large.
Running away what would happen is that you're going to face some ping pong
game here where we are going to start from this point going the other side
because your offer is just too big so you want to balance between the two and
it's hard to reach this point here when you do the back of the pick pocketing.
When you do the ping pong, the third consideration is to check that
your are which is your excuse, should always decrease after each iteration.
Whenever you change beta1 beta0 you're supposed to descend the curve.
So it should the risk should decrease.
Finally you declare convergence.
If you start to decrease by a very small Davis step.
Lets about repeat until convergence,
this convergence is actually when your risk value, is really having now
as you change your betas as changing by very, very, very small value.
So in this case you could declare convergence given some
value that’s not a very small value.
So how about normal equations?
For normal equation one consideration is what to do if X transpose X is not
invertible, which means that we can't calculate the betas because we can't have
the X transpose X minus one value, so in this case, this can happen in two cases.
Either you have too many features, as compared to the number of examples.
For example you have 50 examples but
we have 500 features describing those examples.
Or you have features that are linearly dependent, for
example you have both the weight in pounds and the weights in kilos in your data.
So in this case you have to work with your data a little bit before to
remove redundant features.
Maybe remove the spurious features and
reduce and do some feature selection of your data.



